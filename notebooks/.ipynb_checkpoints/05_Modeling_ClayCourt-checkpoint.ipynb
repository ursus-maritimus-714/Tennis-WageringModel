{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa24a63",
   "metadata": {},
   "source": [
    "## Introduction to Modeling (Clay Court Version)\n",
    "\n",
    "In the previous stage (see Workbook 4; Preprocessing_Training_Clay), two simple benchmark models were generated:\n",
    "\n",
    "* \"Dummy\" Model, where the mean % total points won for given player in the training split (75% of hard court data from 2012-2019) was used to predict % total points won by a given player in a given match: \n",
    "    * Mean error (RMSE): 6.65% Train; 6.54% Test\n",
    "* Multivariate linear model including only ATP rankings (raw and matchup-differential) information in the same training split: \n",
    "    * Mean error/Standard Deviation (RMSE): 6.55% (.07%) Train; 6.42% Test\n",
    "* Here, the entire set of raw and differential predictive features (~150) is used to predict the target of % total points won by a given player in a given match. This is the clay court version; hard court prediction is conducted in a separate workbook (05_ModelingHardCourt).\n",
    "* Because Clay Court matches constitute only ~30% of the total sample, for the Clay Court model (see notebook 05_Modeling_Claycourt) an additional 3 years were used for modeling (2012-2019), with 2009-2011 additionally used for past performance match stats accrual for predictive feature generation. \n",
    "     * For the Hard Court model, data from years 2015-2019 are used in modeling, with an additional 3 years prior to that (2012-2014) used for past performance match stats accrual for predictive feature generation.\n",
    "    * These ranges were systematically determined to be optimal for the available data in the original Tennis Pediction Project (see Reporting folder for that project for data, figures and analysis)\n",
    "* A threshold of minimum of 20 prior matches for BOTH players in a given match to be predicted on is employed in the modeling stage. Not surprisingly, prediction accuracy is sensitive to the amount of data available to generate predictive features, as well as to the amount of data available to train and test the model. Critically, matches filtered out in the present stage WERE used in previous stages for stats accrual/feature development (though those matches filtered out in the initial stage WERE NOT used in feature accrual; see below)\n",
    "    * As a reminder, in the initial stage (see Workbook 1) of the project, matches played on grass (too low a sample size; also removed Davis up and Olympics matches for same reason as well as for their \"odd\" contexts) and matches where one player withdrew (usually for injury reason) either before the match or early on in the match were filtered out and NOT included in feature generation. \n",
    "* Gradient Boosting Regression model was determined to yield the best prediction for this dataset in the original Tennis Prediction Project and is also used presently, with the hyperparameters determined to be optimal in the original project.\n",
    "* Finally, and the critical new addition in this iteration, the full best model is run both with and without the implied probabilities (with vig removed!) derived from Dan Westin's historical wagering odds archive (http://www.tennis-data.co.uk/alldata.php) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b3b3a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318c8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133d431",
   "metadata": {},
   "source": [
    "### Load and Filter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d7aaa",
   "metadata": {},
   "source": [
    "Filtering parameters identical to in dummy/simple modeling stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af618860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_pts_won%</th>\n",
       "      <th>p_sv_pts_won%</th>\n",
       "      <th>p_ret_pts_won%</th>\n",
       "      <th>p_ace%</th>\n",
       "      <th>p_aced%</th>\n",
       "      <th>p_bp_save%</th>\n",
       "      <th>p_bp_convert%</th>\n",
       "      <th>t_id</th>\n",
       "      <th>t_date</th>\n",
       "      <th>tour_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>p_tot_pts_l6_diff</th>\n",
       "      <th>p_tot_pts_l6_decay_diff</th>\n",
       "      <th>p_matches_surf_diff</th>\n",
       "      <th>p_stam_adj_fatigue_diff</th>\n",
       "      <th>p_stam_adj_fatigue_decay_diff</th>\n",
       "      <th>p_H2H_diff</th>\n",
       "      <th>p_H2H_pts_won%_diff</th>\n",
       "      <th>p_IP_NV</th>\n",
       "      <th>p_IP_NV_diff</th>\n",
       "      <th>m_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.64</td>\n",
       "      <td>59.46</td>\n",
       "      <td>32.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>9.33</td>\n",
       "      <td>40.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>2019-0439</td>\n",
       "      <td>20190715</td>\n",
       "      <td>2019_18</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>132.490181</td>\n",
       "      <td>113.442950</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.39</td>\n",
       "      <td>-43.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.38</td>\n",
       "      <td>59.77</td>\n",
       "      <td>37.33</td>\n",
       "      <td>1.15</td>\n",
       "      <td>5.33</td>\n",
       "      <td>42.86</td>\n",
       "      <td>66.67</td>\n",
       "      <td>2019-0439</td>\n",
       "      <td>20190715</td>\n",
       "      <td>2019_18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>35.647668</td>\n",
       "      <td>26.735751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.58</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.80</td>\n",
       "      <td>56.36</td>\n",
       "      <td>33.33</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.52</td>\n",
       "      <td>42.86</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2019-7694</td>\n",
       "      <td>20190520</td>\n",
       "      <td>2019_16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.605416</td>\n",
       "      <td>-8.704062</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.94</td>\n",
       "      <td>25.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.78</td>\n",
       "      <td>47.92</td>\n",
       "      <td>34.55</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.82</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>2019-M009</td>\n",
       "      <td>20190513</td>\n",
       "      <td>2019_15</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>168.759630</td>\n",
       "      <td>148.728814</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.42</td>\n",
       "      <td>-69.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.04</td>\n",
       "      <td>60.26</td>\n",
       "      <td>37.97</td>\n",
       "      <td>3.85</td>\n",
       "      <td>6.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>2019-M009</td>\n",
       "      <td>20190513</td>\n",
       "      <td>2019_15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>111.455108</td>\n",
       "      <td>83.591331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.64</td>\n",
       "      <td>-12.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_pts_won%  p_sv_pts_won%  p_ret_pts_won%  p_ace%  p_aced%  p_bp_save%  \\\n",
       "0       45.64          59.46           32.00    4.05     9.33       40.00   \n",
       "1       49.38          59.77           37.33    1.15     5.33       42.86   \n",
       "2       43.80          56.36           33.33    5.45     1.52       42.86   \n",
       "3       40.78          47.92           34.55    2.08     1.82       33.33   \n",
       "4       49.04          60.26           37.97    3.85     6.33       25.00   \n",
       "\n",
       "   p_bp_convert%       t_id    t_date  tour_wk  ... p_tot_pts_l6_diff  \\\n",
       "0          33.33  2019-0439  20190715  2019_18  ...              55.0   \n",
       "1          66.67  2019-0439  20190715  2019_18  ...               0.0   \n",
       "2          20.00  2019-7694  20190520  2019_16  ...              -0.0   \n",
       "3          33.33  2019-M009  20190513  2019_15  ...             117.0   \n",
       "4          57.14  2019-M009  20190513  2019_15  ...               0.0   \n",
       "\n",
       "  p_tot_pts_l6_decay_diff  p_matches_surf_diff  p_stam_adj_fatigue_diff  \\\n",
       "0                    55.0                -90.0               132.490181   \n",
       "1                     0.0                 -9.0                35.647668   \n",
       "2                    -0.0                  1.0               -11.605416   \n",
       "3                   117.0                -28.0               168.759630   \n",
       "4                     0.0                -48.0               111.455108   \n",
       "\n",
       "   p_stam_adj_fatigue_decay_diff  p_H2H_diff  p_H2H_pts_won%_diff  p_IP_NV  \\\n",
       "0                     113.442950        -0.0                  NaN    28.39   \n",
       "1                      26.735751         0.0                  NaN    46.58   \n",
       "2                      -8.704062        -0.0                  NaN    62.94   \n",
       "3                     148.728814        -0.0                  NaN    15.42   \n",
       "4                      83.591331         0.0                  NaN    43.64   \n",
       "\n",
       "   p_IP_NV_diff  m_outcome  \n",
       "0        -43.22          0  \n",
       "1         -6.84          1  \n",
       "2         25.88          0  \n",
       "3        -69.16          0  \n",
       "4        -12.72          1  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ths is the file and analysis data range used for the main hard court analysis\n",
    "df = pd.read_csv('../data/df_player_all_clay.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15247e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8c96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data range used for the main analysis for clay courts- 2012-2019 in model; 2009-2011 used for additional stats accrual \"runway\"\n",
    "df_filter = df[~df['tour_wk'].str.contains(\"2009\")] \n",
    "df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2010\")]\n",
    "df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2011\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2012\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2013\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2014\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2015\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2016\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2017\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2018\")]\n",
    "#df_filter = df_filter[~df_filter['tour_wk'].str.contains(\"2019\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995cacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to only matches played on hard courts\n",
    "#df_filter2 = df_filter.loc[(df_filter[\"t_surf\"] == 2)]\n",
    "#df_filter2 = df_filter.loc[(df_filter[\"t_surf\"] == 2) & (df_filter[\"p_matches_surf\"] > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bdde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now also will remove BOTH players from individual matches remaining in the surface-specific sample already filtered by year range\n",
    "# where one or both players has played N or fewer matches prior to the one to be predicted on.\n",
    "# Threshold of minimum of 20 was established as optimal in the orignal Tennis Prediction Project\n",
    "df_low = df_filter.loc[df_filter['p_matches_surf'] <= 20, 'm_num']\n",
    "df_filter2 = df_filter[~df_filter['m_num'].isin(df_low)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f32222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell used only for final presentation figure where hard court sample N was reduced to be equal to that of the clay court sample\n",
    "# Best model (Gradient Boosting Regressor) was run at this N for that figure using the same hyperparameters as for full sample.\n",
    "#df_filter3 = df_filter3.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0170740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pared down to just the predictive features(both raw and player-opponent differential for match being predicted on), and the target feature itself ( player % pts won in the mtch being predicted on)\n",
    "# All features are derived from data available prior to any given match being predicted on. No data leakage!\n",
    "# This feature set DOES NOT INCLUDE implied odds (vig removed) from Dan Westin's historical wagering lines. See cell below for that iteration.\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_rank\", \"p_log_rank\", \"p_rank_pts\", \"p_ent\", \"p_hd\", \"p_ht\", \"p_age\", \"p_matches_surf\", \"p_H2H_w\", \"p_H2H_pts_won%\", \"p_pts_won%_l60_decay\", \"p_pts_won%_l60_decay_IO\", \"p_pts_won%_l10\", \"p_SOS_adj_pts_won%_l60_decay\", \"p_SOS_adj_pts_won%_l60_decay_IO\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted\", \"p_SOS_adj_pts_won%_l10\", \"p_sv_pts_won%_l60_decay\", \"p_sv_pts_won%_l10\", \"p_SOS_adj_sv_pts_won%_l60_decay\", \"p_SOS_adj_sv_pts_won%_l10\", \"p_ret_pts_won%_l60_decay\", \"p_ret_pts_won%_l10\", \"p_SOS_adj_ret_pts_won%_l60_decay\", \"p_SOS_adj_ret_pts_won%_l10\", \"p_ace%_l60_decay\", \"p_ace%_l10\", \"p_SOS_adj_ace%_l60_decay\", \"p_SOS_adj_ace%_l10\", \"p_aced%_l60_decay\", \"p_aced%_l10\", \"p_SOS_adj_aced%_l60_decay\", \"p_SOS_adj_aced%_l10\", \"p_bp_save%_l60\", \"p_bp_save%_l10\", \"p_SOS_adj_bp_save%_l60\", \"p_SOS_adj_bp_save%_l10\", \"p_bp_convert%_l60\", \"p_bp_convert%_l10\", \"p_SOS_adj_bp_convert%_l60\", \"p_SOS_adj_bp_convert%_l10\", \"p_pts_won%_std_l60_decay\",\"p_sv_pts_won%_std_l60_decay\", \"p_ret_pts_won%_std_l60_decay\",\"p_m_time_last\", \"p_tot_time_l6\", \"p_tot_time_l6_decay\", \"p_tot_pts_last\", \"p_tot_pts_l6\", \"p_tot_pts_l6_decay\", \"p_stamina_adj_fatigue\", \"p_stamina_adj_fatigue_decay\", \"high_t_ace_p_ace\", \"high_t_ace_p_aced\", \"p_opp_rank_diff\", \"p_opp_log_rank_diff\", \"p_opp_rank_pts_diff\", \"p_ent_diff\", \"p_opp_ht_diff\", \"p_opp_age_diff\", \"p_L_opp_R\", \"p_HCA_opp_N\", \"p_pts_won%_l60_decay_diff\", \"p_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted_diff\", \"p_pts_won%_l10_diff\", \"p_SOS_adj_pts_won%_l10_diff\", \"p_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_pts_won%_l60_decay_diff\", \"p_sv_pts_won%_l10_diff\", \"p_SOS_adj_sv_pts_won%_l10_diff\", \"p_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_pts_won%_l60_decay_diff\", \"p_ret_pts_won%_l10_diff\", \"p_SOS_adj_ret_pts_won%_l10_diff\", \"p_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_sv_opp_ret_pts_won%_l10_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l10_diff\", \"p_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_ret_opp_sv_pts_won%_l10_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l10_diff\", \"p_ace%_l60_decay_diff\", \"p_SOS_adj_ace%_l60_decay_diff\", \"p_ace%_l10_diff\", \"p_SOS_adj_ace%_l10_diff\", \"p_aced%_l60_decay_diff\", \"p_SOS_adj_aced%_l60_decay_diff\", \"p_aced%_l10_diff\", \"p_SOS_adj_aced%_l10_diff\", \"p_ace%_opp_aced%_l60_decay_diff\", \"p_SOS_adj_ace%_opp_aced%_l60_decay_diff\", \"p_ace%_opp_aced%_l10_diff\", \"p_SOS_adj_ace%_opp_aced%_l10_diff\", \"p_aced%_opp_ace%_l60_decay_diff\", \"p_SOS_adj_aced%_opp_ace%_l60_decay_diff\", \"p_aced%_opp_ace%_l10_diff\", \"p_SOS_adj_aced%_opp_ace%_l10_diff\", \"p_bp_save%_l60_diff\", \"p_SOS_adj_bp_save%_l60_diff\", \"p_bp_save%_l10_diff\", \"p_SOS_adj_bp_save%_l10_diff\", \"p_bp_convert%_l60_diff\", \"p_SOS_adj_bp_convert%_l60_diff\", \"p_bp_convert%_l10_diff\", \"p_SOS_adj_bp_convert%_l10_diff\", \"p_bp_convert%_opp_bp_save%_l60_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l60_diff\", \"p_bp_convert%_opp_bp_save%_l10_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l10_diff\", \"p_bp_save%_opp_bp_convert%_l60_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l60_diff\", \"p_bp_save%_opp_bp_convert%_l10_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l10_diff\", \"p_pts_won%_std_l60_decay_diff\", 'p_sv_pts_won%_std_l60_decay_diff','p_ret_pts_won%_std_l60_decay_diff', \"p_m_time_last_diff\", \"p_tot_time_l6_diff\", \"p_tot_time_l6_decay_diff\", \"p_tot_pts_last_diff\", \"p_tot_pts_l6_diff\", \"p_tot_pts_l6_decay_diff\", \"p_matches_surf_diff\", \"p_stam_adj_fatigue_diff\", \"p_stam_adj_fatigue_decay_diff\", \"p_H2H_diff\", \"p_H2H_pts_won%_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fe3ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pared down to just the predictive features(both raw and player-opponent differential for match being predicted on), and the target feature itself ( player % pts won in the mtch being predicted on)\n",
    "# All features are derived from data available prior to any given match being predicted on. No data leakage!\n",
    "# This feature set DOES INCLUDE RAW implied odds (vig removed) from Dan Westin's historical wagering lines. See cell below for that iteration.\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_rank\", \"p_log_rank\", \"p_rank_pts\", \"p_ent\", \"p_hd\", \"p_ht\", \"p_age\", \"p_matches_surf\", \"p_H2H_w\", \"p_H2H_pts_won%\", \"p_pts_won%_l60_decay\", \"p_pts_won%_l60_decay_IO\", \"p_pts_won%_l10\", \"p_SOS_adj_pts_won%_l60_decay\", \"p_SOS_adj_pts_won%_l60_decay_IO\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted\", \"p_SOS_adj_pts_won%_l10\", \"p_sv_pts_won%_l60_decay\", \"p_sv_pts_won%_l10\", \"p_SOS_adj_sv_pts_won%_l60_decay\", \"p_SOS_adj_sv_pts_won%_l10\", \"p_ret_pts_won%_l60_decay\", \"p_ret_pts_won%_l10\", \"p_SOS_adj_ret_pts_won%_l60_decay\", \"p_SOS_adj_ret_pts_won%_l10\", \"p_ace%_l60_decay\", \"p_ace%_l10\", \"p_SOS_adj_ace%_l60_decay\", \"p_SOS_adj_ace%_l10\", \"p_aced%_l60_decay\", \"p_aced%_l10\", \"p_SOS_adj_aced%_l60_decay\", \"p_SOS_adj_aced%_l10\", \"p_bp_save%_l60\", \"p_bp_save%_l10\", \"p_SOS_adj_bp_save%_l60\", \"p_SOS_adj_bp_save%_l10\", \"p_bp_convert%_l60\", \"p_bp_convert%_l10\", \"p_SOS_adj_bp_convert%_l60\", \"p_SOS_adj_bp_convert%_l10\", \"p_pts_won%_std_l60_decay\",\"p_sv_pts_won%_std_l60_decay\", \"p_ret_pts_won%_std_l60_decay\",\"p_m_time_last\", \"p_tot_time_l6\", \"p_tot_time_l6_decay\", \"p_tot_pts_last\", \"p_tot_pts_l6\", \"p_tot_pts_l6_decay\", \"p_stamina_adj_fatigue\", \"p_stamina_adj_fatigue_decay\", \"high_t_ace_p_ace\", \"high_t_ace_p_aced\", \"p_opp_rank_diff\", \"p_opp_log_rank_diff\", \"p_opp_rank_pts_diff\", \"p_ent_diff\", \"p_opp_ht_diff\", \"p_opp_age_diff\", \"p_L_opp_R\", \"p_HCA_opp_N\", \"p_pts_won%_l60_decay_diff\", \"p_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted_diff\", \"p_pts_won%_l10_diff\", \"p_SOS_adj_pts_won%_l10_diff\", \"p_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_pts_won%_l60_decay_diff\", \"p_sv_pts_won%_l10_diff\", \"p_SOS_adj_sv_pts_won%_l10_diff\", \"p_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_pts_won%_l60_decay_diff\", \"p_ret_pts_won%_l10_diff\", \"p_SOS_adj_ret_pts_won%_l10_diff\", \"p_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_sv_opp_ret_pts_won%_l10_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l10_diff\", \"p_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_ret_opp_sv_pts_won%_l10_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l10_diff\", \"p_ace%_l60_decay_diff\", \"p_SOS_adj_ace%_l60_decay_diff\", \"p_ace%_l10_diff\", \"p_SOS_adj_ace%_l10_diff\", \"p_aced%_l60_decay_diff\", \"p_SOS_adj_aced%_l60_decay_diff\", \"p_aced%_l10_diff\", \"p_SOS_adj_aced%_l10_diff\", \"p_ace%_opp_aced%_l60_decay_diff\", \"p_SOS_adj_ace%_opp_aced%_l60_decay_diff\", \"p_ace%_opp_aced%_l10_diff\", \"p_SOS_adj_ace%_opp_aced%_l10_diff\", \"p_aced%_opp_ace%_l60_decay_diff\", \"p_SOS_adj_aced%_opp_ace%_l60_decay_diff\", \"p_aced%_opp_ace%_l10_diff\", \"p_SOS_adj_aced%_opp_ace%_l10_diff\", \"p_bp_save%_l60_diff\", \"p_SOS_adj_bp_save%_l60_diff\", \"p_bp_save%_l10_diff\", \"p_SOS_adj_bp_save%_l10_diff\", \"p_bp_convert%_l60_diff\", \"p_SOS_adj_bp_convert%_l60_diff\", \"p_bp_convert%_l10_diff\", \"p_SOS_adj_bp_convert%_l10_diff\", \"p_bp_convert%_opp_bp_save%_l60_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l60_diff\", \"p_bp_convert%_opp_bp_save%_l10_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l10_diff\", \"p_bp_save%_opp_bp_convert%_l60_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l60_diff\", \"p_bp_save%_opp_bp_convert%_l10_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l10_diff\", \"p_pts_won%_std_l60_decay_diff\", 'p_sv_pts_won%_std_l60_decay_diff','p_ret_pts_won%_std_l60_decay_diff', \"p_m_time_last_diff\", \"p_tot_time_l6_diff\", \"p_tot_time_l6_decay_diff\", \"p_tot_pts_last_diff\", \"p_tot_pts_l6_diff\", \"p_tot_pts_l6_decay_diff\", \"p_matches_surf_diff\", \"p_stam_adj_fatigue_diff\", \"p_stam_adj_fatigue_decay_diff\", \"p_H2H_diff\", \"p_H2H_pts_won%_diff\", \"p_IP_NV\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "857df0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pared down to just the predictive features(both raw and player-opponent differential for match being predicted on), and the target feature itself ( player % pts won in the mtch being predicted on)\n",
    "# All features are derived from data available prior to any given match being predicted on. No data leakage!\n",
    "# This feature set DOES INCLUDE DIFFERENTIAL implied odds (vig removed) from Dan Westin's historical wagering lines. See cell below for that iteration.\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_rank\", \"p_log_rank\", \"p_rank_pts\", \"p_ent\", \"p_hd\", \"p_ht\", \"p_age\", \"p_matches_surf\", \"p_H2H_w\", \"p_H2H_pts_won%\", \"p_pts_won%_l60_decay\", \"p_pts_won%_l60_decay_IO\", \"p_pts_won%_l10\", \"p_SOS_adj_pts_won%_l60_decay\", \"p_SOS_adj_pts_won%_l60_decay_IO\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted\", \"p_SOS_adj_pts_won%_l10\", \"p_sv_pts_won%_l60_decay\", \"p_sv_pts_won%_l10\", \"p_SOS_adj_sv_pts_won%_l60_decay\", \"p_SOS_adj_sv_pts_won%_l10\", \"p_ret_pts_won%_l60_decay\", \"p_ret_pts_won%_l10\", \"p_SOS_adj_ret_pts_won%_l60_decay\", \"p_SOS_adj_ret_pts_won%_l10\", \"p_ace%_l60_decay\", \"p_ace%_l10\", \"p_SOS_adj_ace%_l60_decay\", \"p_SOS_adj_ace%_l10\", \"p_aced%_l60_decay\", \"p_aced%_l10\", \"p_SOS_adj_aced%_l60_decay\", \"p_SOS_adj_aced%_l10\", \"p_bp_save%_l60\", \"p_bp_save%_l10\", \"p_SOS_adj_bp_save%_l60\", \"p_SOS_adj_bp_save%_l10\", \"p_bp_convert%_l60\", \"p_bp_convert%_l10\", \"p_SOS_adj_bp_convert%_l60\", \"p_SOS_adj_bp_convert%_l10\", \"p_pts_won%_std_l60_decay\",\"p_sv_pts_won%_std_l60_decay\", \"p_ret_pts_won%_std_l60_decay\",\"p_m_time_last\", \"p_tot_time_l6\", \"p_tot_time_l6_decay\", \"p_tot_pts_last\", \"p_tot_pts_l6\", \"p_tot_pts_l6_decay\", \"p_stamina_adj_fatigue\", \"p_stamina_adj_fatigue_decay\", \"high_t_ace_p_ace\", \"high_t_ace_p_aced\", \"p_opp_rank_diff\", \"p_opp_log_rank_diff\", \"p_opp_rank_pts_diff\", \"p_ent_diff\", \"p_opp_ht_diff\", \"p_opp_age_diff\", \"p_L_opp_R\", \"p_HCA_opp_N\", \"p_pts_won%_l60_decay_diff\", \"p_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted_diff\", \"p_pts_won%_l10_diff\", \"p_SOS_adj_pts_won%_l10_diff\", \"p_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_pts_won%_l60_decay_diff\", \"p_sv_pts_won%_l10_diff\", \"p_SOS_adj_sv_pts_won%_l10_diff\", \"p_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_pts_won%_l60_decay_diff\", \"p_ret_pts_won%_l10_diff\", \"p_SOS_adj_ret_pts_won%_l10_diff\", \"p_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_sv_opp_ret_pts_won%_l10_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l10_diff\", \"p_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_ret_opp_sv_pts_won%_l10_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l10_diff\", \"p_ace%_l60_decay_diff\", \"p_SOS_adj_ace%_l60_decay_diff\", \"p_ace%_l10_diff\", \"p_SOS_adj_ace%_l10_diff\", \"p_aced%_l60_decay_diff\", \"p_SOS_adj_aced%_l60_decay_diff\", \"p_aced%_l10_diff\", \"p_SOS_adj_aced%_l10_diff\", \"p_ace%_opp_aced%_l60_decay_diff\", \"p_SOS_adj_ace%_opp_aced%_l60_decay_diff\", \"p_ace%_opp_aced%_l10_diff\", \"p_SOS_adj_ace%_opp_aced%_l10_diff\", \"p_aced%_opp_ace%_l60_decay_diff\", \"p_SOS_adj_aced%_opp_ace%_l60_decay_diff\", \"p_aced%_opp_ace%_l10_diff\", \"p_SOS_adj_aced%_opp_ace%_l10_diff\", \"p_bp_save%_l60_diff\", \"p_SOS_adj_bp_save%_l60_diff\", \"p_bp_save%_l10_diff\", \"p_SOS_adj_bp_save%_l10_diff\", \"p_bp_convert%_l60_diff\", \"p_SOS_adj_bp_convert%_l60_diff\", \"p_bp_convert%_l10_diff\", \"p_SOS_adj_bp_convert%_l10_diff\", \"p_bp_convert%_opp_bp_save%_l60_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l60_diff\", \"p_bp_convert%_opp_bp_save%_l10_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l10_diff\", \"p_bp_save%_opp_bp_convert%_l60_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l60_diff\", \"p_bp_save%_opp_bp_convert%_l10_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l10_diff\", \"p_pts_won%_std_l60_decay_diff\", 'p_sv_pts_won%_std_l60_decay_diff','p_ret_pts_won%_std_l60_decay_diff', \"p_m_time_last_diff\", \"p_tot_time_l6_diff\", \"p_tot_time_l6_decay_diff\", \"p_tot_pts_last_diff\", \"p_tot_pts_l6_diff\", \"p_tot_pts_l6_decay_diff\", \"p_matches_surf_diff\", \"p_stam_adj_fatigue_diff\", \"p_stam_adj_fatigue_decay_diff\", \"p_H2H_diff\", \"p_H2H_pts_won%_diff\", \"p_IP_NV_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5d69147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pared down to just the predictive features(both raw and player-opponent differential for match being predicted on), and the target feature itself ( player % pts won in the mtch being predicted on)\n",
    "# All features are derived from data available prior to any given match being predicted on. No data leakage!\n",
    "# This feature set DOES INCLUDE RAW AND DIFFERENTIAL implied odds (vig removed) from Dan Westin's historical wagering lines. See cell below for that iteration.\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_rank\", \"p_log_rank\", \"p_rank_pts\", \"p_ent\", \"p_hd\", \"p_ht\", \"p_age\", \"p_matches_surf\", \"p_H2H_w\", \"p_H2H_pts_won%\", \"p_pts_won%_l60_decay\", \"p_pts_won%_l60_decay_IO\", \"p_pts_won%_l10\", \"p_SOS_adj_pts_won%_l60_decay\", \"p_SOS_adj_pts_won%_l60_decay_IO\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted\", \"p_SOS_adj_pts_won%_l10\", \"p_sv_pts_won%_l60_decay\", \"p_sv_pts_won%_l10\", \"p_SOS_adj_sv_pts_won%_l60_decay\", \"p_SOS_adj_sv_pts_won%_l10\", \"p_ret_pts_won%_l60_decay\", \"p_ret_pts_won%_l10\", \"p_SOS_adj_ret_pts_won%_l60_decay\", \"p_SOS_adj_ret_pts_won%_l10\", \"p_ace%_l60_decay\", \"p_ace%_l10\", \"p_SOS_adj_ace%_l60_decay\", \"p_SOS_adj_ace%_l10\", \"p_aced%_l60_decay\", \"p_aced%_l10\", \"p_SOS_adj_aced%_l60_decay\", \"p_SOS_adj_aced%_l10\", \"p_bp_save%_l60\", \"p_bp_save%_l10\", \"p_SOS_adj_bp_save%_l60\", \"p_SOS_adj_bp_save%_l10\", \"p_bp_convert%_l60\", \"p_bp_convert%_l10\", \"p_SOS_adj_bp_convert%_l60\", \"p_SOS_adj_bp_convert%_l10\", \"p_pts_won%_std_l60_decay\",\"p_sv_pts_won%_std_l60_decay\", \"p_ret_pts_won%_std_l60_decay\",\"p_m_time_last\", \"p_tot_time_l6\", \"p_tot_time_l6_decay\", \"p_tot_pts_last\", \"p_tot_pts_l6\", \"p_tot_pts_l6_decay\", \"p_stamina_adj_fatigue\", \"p_stamina_adj_fatigue_decay\", \"high_t_ace_p_ace\", \"high_t_ace_p_aced\", \"p_opp_rank_diff\", \"p_opp_log_rank_diff\", \"p_opp_rank_pts_diff\", \"p_ent_diff\", \"p_opp_ht_diff\", \"p_opp_age_diff\", \"p_L_opp_R\", \"p_HCA_opp_N\", \"p_pts_won%_l60_decay_diff\", \"p_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_diff\", \"p_SOS_adj_pts_won%_l60_decay_IO_weighted_diff\", \"p_pts_won%_l10_diff\", \"p_SOS_adj_pts_won%_l10_diff\", \"p_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_pts_won%_l60_decay_diff\", \"p_sv_pts_won%_l10_diff\", \"p_SOS_adj_sv_pts_won%_l10_diff\", \"p_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_pts_won%_l60_decay_diff\", \"p_ret_pts_won%_l10_diff\", \"p_SOS_adj_ret_pts_won%_l10_diff\", \"p_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l60_decay_diff\", \"p_sv_opp_ret_pts_won%_l10_diff\", \"p_SOS_adj_sv_opp_ret_pts_won%_l10_diff\", \"p_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l60_decay_diff\", \"p_ret_opp_sv_pts_won%_l10_diff\", \"p_SOS_adj_ret_opp_sv_pts_won%_l10_diff\", \"p_ace%_l60_decay_diff\", \"p_SOS_adj_ace%_l60_decay_diff\", \"p_ace%_l10_diff\", \"p_SOS_adj_ace%_l10_diff\", \"p_aced%_l60_decay_diff\", \"p_SOS_adj_aced%_l60_decay_diff\", \"p_aced%_l10_diff\", \"p_SOS_adj_aced%_l10_diff\", \"p_ace%_opp_aced%_l60_decay_diff\", \"p_SOS_adj_ace%_opp_aced%_l60_decay_diff\", \"p_ace%_opp_aced%_l10_diff\", \"p_SOS_adj_ace%_opp_aced%_l10_diff\", \"p_aced%_opp_ace%_l60_decay_diff\", \"p_SOS_adj_aced%_opp_ace%_l60_decay_diff\", \"p_aced%_opp_ace%_l10_diff\", \"p_SOS_adj_aced%_opp_ace%_l10_diff\", \"p_bp_save%_l60_diff\", \"p_SOS_adj_bp_save%_l60_diff\", \"p_bp_save%_l10_diff\", \"p_SOS_adj_bp_save%_l10_diff\", \"p_bp_convert%_l60_diff\", \"p_SOS_adj_bp_convert%_l60_diff\", \"p_bp_convert%_l10_diff\", \"p_SOS_adj_bp_convert%_l10_diff\", \"p_bp_convert%_opp_bp_save%_l60_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l60_diff\", \"p_bp_convert%_opp_bp_save%_l10_diff\", \"p_SOS_adj_bp_convert%_opp_bp_save%_l10_diff\", \"p_bp_save%_opp_bp_convert%_l60_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l60_diff\", \"p_bp_save%_opp_bp_convert%_l10_diff\", \"p_SOS_adj_bp_save%_opp_bp_convert%_l10_diff\", \"p_pts_won%_std_l60_decay_diff\", 'p_sv_pts_won%_std_l60_decay_diff','p_ret_pts_won%_std_l60_decay_diff', \"p_m_time_last_diff\", \"p_tot_time_l6_diff\", \"p_tot_time_l6_decay_diff\", \"p_tot_pts_last_diff\", \"p_tot_pts_l6_diff\", \"p_tot_pts_l6_decay_diff\", \"p_matches_surf_diff\", \"p_stam_adj_fatigue_diff\", \"p_stam_adj_fatigue_decay_diff\", \"p_H2H_diff\", \"p_H2H_pts_won%_diff\", \"p_IP_NV\", \"p_IP_NV_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a72295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY Raw Implied Odds As a Player Predictive Feature\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_IP_NV\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY Differential Implied Odds As a Player Predictive Feature\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_IP_NV_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fb50c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY Differential AND RAW Implied Odds As Player Predictive Features\n",
    "df_model1 = df_filter2[[\"p_pts_won%\", \"t_indoor\", \"t_alt\", \"t_ace%_last\", \"t_lvl\", \"t_draw_size\", \"t_rd_num\", \"m_best_of\", \"p_IP_NV\", \"p_IP_NV_diff\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c9936",
   "metadata": {},
   "source": [
    "### Data Split for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778504df",
   "metadata": {},
   "source": [
    "Identical split as for dummy/simple modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e7f2b6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410.5, 1803.5)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_model1) * .75, len(df_model1) * .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "319fbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replicates EXACT train-test split from dummy and simpler modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_model1.drop(columns='p_pts_won%'), \n",
    "                                                    df_model1[\"p_pts_won%\"], test_size=0.25, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9bd84540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5410,), (1804,))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51897b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5302     50.00\n",
       "15145    45.58\n",
       "4495     47.62\n",
       "7068     42.34\n",
       "4759     50.46\n",
       "         ...  \n",
       "15451    37.89\n",
       "7724     54.01\n",
       "14832    45.14\n",
       "4814     47.73\n",
       "11761    53.42\n",
       "Name: p_pts_won%, Length: 5410, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "86a500f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5410, 9), (1804, 9))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300fd6a4",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bff8c",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model: Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "22473aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pipeline \n",
    "GB_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler(),\n",
    "    GradientBoostingRegressor(random_state= 47)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b247d05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'simpleimputer', 'standardscaler', 'gradientboostingregressor', 'simpleimputer__add_indicator', 'simpleimputer__copy', 'simpleimputer__fill_value', 'simpleimputer__missing_values', 'simpleimputer__strategy', 'simpleimputer__verbose', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'gradientboostingregressor__alpha', 'gradientboostingregressor__ccp_alpha', 'gradientboostingregressor__criterion', 'gradientboostingregressor__init', 'gradientboostingregressor__learning_rate', 'gradientboostingregressor__loss', 'gradientboostingregressor__max_depth', 'gradientboostingregressor__max_features', 'gradientboostingregressor__max_leaf_nodes', 'gradientboostingregressor__min_impurity_decrease', 'gradientboostingregressor__min_impurity_split', 'gradientboostingregressor__min_samples_leaf', 'gradientboostingregressor__min_samples_split', 'gradientboostingregressor__min_weight_fraction_leaf', 'gradientboostingregressor__n_estimators', 'gradientboostingregressor__n_iter_no_change', 'gradientboostingregressor__random_state', 'gradientboostingregressor__subsample', 'gradientboostingregressor__tol', 'gradientboostingregressor__validation_fraction', 'gradientboostingregressor__verbose', 'gradientboostingregressor__warm_start'])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "57b53602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingregressor__n_estimators': [100],\n",
       " 'standardscaler': [StandardScaler()],\n",
       " 'simpleimputer__strategy': ['median'],\n",
       " 'gradientboostingregressor__learning_rate': [0.05],\n",
       " 'gradientboostingregressor__max_depth': [4],\n",
       " 'gradientboostingregressor__max_features': [9]}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define Grid Parameters. These were found to be optimal for prediction with the full feature set in the original Tennis Prediction Project\n",
    "\n",
    "n_est = [100]\n",
    "learning_rate = [.05]\n",
    "max_depth = [4]\n",
    "max_features = [9] \n",
    "\n",
    "\n",
    "grid_params = {\n",
    "        'gradientboostingregressor__n_estimators': n_est,\n",
    "        'standardscaler': [StandardScaler()],\n",
    "        'simpleimputer__strategy': ['median'],\n",
    "        'gradientboostingregressor__learning_rate': learning_rate,\n",
    "        'gradientboostingregressor__max_depth': max_depth,\n",
    "        'gradientboostingregressor__max_features': max_features\n",
    "}\n",
    "grid_params\n",
    "\n",
    "#Best Params:\n",
    "#{'gradientboostingregressor__learning_rate': 0.05,\n",
    " #'gradientboostingregressor__max_depth': 4,\n",
    " #'gradientboostingregressor__max_features': 9,\n",
    " #'gradientboostingregressor__n_estimators': 100,\n",
    "#'simpleimputer__strategy': 'median',\n",
    " #'standardscaler': StandardScaler()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb48abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `GridSearchCV` with the gradient boosting pipeline, passing in the above `grid_params`\n",
    "#dict for parameters to evaluate, 5-fold cross-validation\n",
    "gb_grid_cv = GridSearchCV(GB_pipe, param_grid=grid_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "330fc1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('gradientboostingregressor',\n",
       "                                        GradientBoostingRegressor(random_state=47))]),\n",
       "             param_grid={'gradientboostingregressor__learning_rate': [0.05],\n",
       "                         'gradientboostingregressor__max_depth': [4],\n",
       "                         'gradientboostingregressor__max_features': [9],\n",
       "                         'gradientboostingregressor__n_estimators': [100],\n",
       "                         'simpleimputer__strategy': ['median'],\n",
       "                         'standardscaler': [StandardScaler()]})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conduct the grid search. \n",
    "gb_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "57d15a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingregressor__learning_rate': 0.05,\n",
       " 'gradientboostingregressor__max_depth': 4,\n",
       " 'gradientboostingregressor__max_features': 9,\n",
       " 'gradientboostingregressor__n_estimators': 100,\n",
       " 'simpleimputer__strategy': 'median',\n",
       " 'standardscaler': StandardScaler()}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best params (`best_params_` attribute) from the grid search\n",
    "gb_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f35b3",
   "metadata": {},
   "source": [
    "### Best Gradient Boosting Model Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820c285",
   "metadata": {},
   "source": [
    "#### R-squared (COD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6dc56798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22940993, 0.26988417, 0.25424576, 0.27628135, 0.24996717])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation defaults to R^2 metric for scoring regression\n",
    "gb_best_cv_results = cross_validate(gb_grid_cv.best_estimator_, X_train, y_train, cv=5)\n",
    "gb_best_scores = gb_best_cv_results['test_score']\n",
    "gb_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b28a43c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25595767637372957, 0.01643532075325664)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "np.mean(gb_best_scores), np.std(gb_best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91478b1",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e18c5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_neg_mae = cross_validate(gb_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fcd81789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.483158093248276, 0.06033597125372961)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "gb_mae_mean = np.mean(-1 * gb_neg_mae['test_score'])\n",
    "gb_mae_std = np.std(-1 * gb_neg_mae['test_score'])\n",
    "gb_mae_mean, gb_mae_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6d131fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.584252474475177"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "mean_absolute_error(y_test, gb_grid_cv.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e05fa0",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "680649e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_neg_mse = cross_validate(gb_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5bf5c623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.829002156282556, 0.8535202623625847)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "gb_mse_mean = np.mean(-1 * gb_neg_mse['test_score'])\n",
    "gb_mse_std = np.std(-1 * gb_neg_mse['test_score'])\n",
    "gb_mse_mean, gb_mse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a347d29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.61527472024141"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "mean_squared_error(y_test, gb_grid_cv.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e2fa6",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "637cc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_neg_rmse = cross_validate(gb_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_root_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "129c9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.729176822127715, 0.07439823302428641)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "gb_rmse_mean = np.mean(-1 * gb_neg_rmse['test_score'])\n",
    "gb_rmse_std = np.std(-1 * gb_neg_rmse['test_score'])\n",
    "gb_rmse_mean, gb_rmse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1bac3e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.797868118562323"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "np.sqrt(mean_squared_error(y_test, gb_grid_cv.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42bbe6",
   "metadata": {},
   "source": [
    "### Best Gradient Boosting Model Feature Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e1ca08e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a barplot of the gradient boosting model's feature importances,\n",
    "#assigning the `feature_importances_` attribute of \n",
    "#`gb_grid_cv.best_estimator_.named_steps.gradientboostingregressor` to the name `imps` to then\n",
    "#create a pandas Series object of the feature importances, with the index given by the\n",
    "#training data column names, sorting the values in descending order\n",
    "plt.subplots(figsize=(20, 10))\n",
    "imps = gb_grid_cv.best_estimator_.named_steps.gradientboostingregressor.feature_importances_\n",
    "rf_feat_imps = pd.Series(imps, index=X_train.columns).sort_values(ascending=False)\n",
    "rf_feat_imps.plot(kind='bar')\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('importance')\n",
    "plt.title('Best gradient boosting regressor feature importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2ad1e",
   "metadata": {},
   "source": [
    "### Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c66adc",
   "metadata": {},
   "source": [
    "Because Gradient Boosting Regressor turned out to be the best of the four models tested (in terms of cross-validation RMSE) for hard courts, a Data Quality Assessment was run on this model to ensure that results are not hindered by sample size. Much more analysis of data size and year range of inclusion is conducted in the final reporting (see Reporting folder of original Tennis Prediction Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [.2, .25, .3, .35, .4, .45, .5, .6, .75, .8, .9, 1.0]\n",
    "train_size, train_scores, test_scores = learning_curve(GB_pipe, X_train, y_train, train_sizes=fractions)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ef1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 5))\n",
    "plt.errorbar(train_size, test_scores_mean, yerr=test_scores_std)\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('CV scores')\n",
    "plt.title('Cross-validation score as training set size increases');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129971e3",
   "metadata": {},
   "source": [
    "## Save Best Model Object From Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gb_grid_cv.best_estimator_\n",
    "best_model.version = '1.0'\n",
    "best_model.pandas_version = pd.__version__\n",
    "best_model.numpy_version = np.__version__\n",
    "best_model.sklearn_version = sklearn_version\n",
    "best_model.X_columns = [col for col in X_train.columns]\n",
    "best_model.build_datetime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "modelpath = '../models'\n",
    "save_file(best_model, 'tennis_HC_model.pkl', modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a907384",
   "metadata": {},
   "source": [
    "## New Conclusions \n",
    "\n",
    "#### Best Full Model Performance WITHOUT Closing Match Odds-Derived Implied Probabilities \n",
    "* The best regression model (also tested were Linear, Random Forest, Hist Gradient Boosting) as determined in the original Tennis Prediction Project (Gradient Boosting), making use of the full set of raw (matchup-independent) and differential (player relative to the other player in the match being predicted on) predictive features: \n",
    "    * The best full model resulted in RMSE(STD): 5.83% (.08%) for training set cross validation and 5.87% for the test set.\n",
    "\n",
    "#### Best Full Model Performance WITH Closing Match Odds-Derived Implied Probabilities (+ Raw Only)\n",
    "* RMSE(STD): 5.76% (.09) for training set cross validation and 5.79% for the test set. \n",
    "    * So adding the closing lines-derived implied odds as a feature to the best model slightly improved model performance\n",
    "\n",
    "#### Best Full Model Performance WITH Closing Match Odds-Derived Implied Probabilities (+ Differential Only)\n",
    "* RMSE(STD): 5.76% (.09) for training set cross validation and 5.79% for the test set. \n",
    "    * So adding the closing lines-derived implied odds as a feature to the best model slightly improved model performance\n",
    "\n",
    "#### Best Full Model Performance WITH Closing Match Odds-Derived Implied Probabilities (+ Raw AND Differential)\n",
    "* RMSE(STD): 5.75% (.09) for training set cross validation and 5.78% for the test set. \n",
    "    * So adding the closing lines-derived implied odds as a feature to the best model slightly improved model performance\n",
    "\n",
    "    \n",
    "#### Model Performance W/ ONLY RAW AND DIFFERENTIAL Closing Match Odds-Derived Implied Probabilities as Predictive Features\n",
    "* RMSE(STD): 5.73% (.07%) for training set cross validation and 5.80% for the test set.\n",
    "    * So, slightly better than the full model, but not incredibly so!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
